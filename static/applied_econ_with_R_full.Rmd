---
title: "Applied Economics with R"
author:
  name: Hans H. Sievertsen
  affiliation: University of Bristol
  email: h.h.sievertsen@bristol.ac.uk
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    theme: lumen 
    highlight: haddock
    code_folding: none
    toc: yes
    toc_depth: 3
    toc_float: yes
    keep_md: true
    css: css/style.css
---




```{r setup, include=FALSE}

require("emo")
library("aewr")
library("tidyverse")
library("skimr")
library("readstata13")
library("sjPlot")
library("psych")
library("openxlsx")
knitr::opts_chunk$set(echo = FALSE)
```

# Welcome!

### Hi!{-}


Welcome to this introduction to Applied Economics with R. This tutorial is written for economics students at the University of Bristol, but everyone is welcome to use it. 


**How this works**

- The tutorial is structured as a complete research project starting with loading the raw data and ending with a chart comparing the estimates across approaches. 
- All data used is directly downloadable (see the next section).You should therefore be able to download and reproduce all results. 
- The tutorial is mainly consists of code blocks  and the resulting output.  Every now and then I include some references to how I would do the same task in Stata or key differences to Stata. 
- This tutorial is a work in progress project, so please let me know if you find mistakes, a particularly unclear sections, or if you have suggestions for improvements (just send an email to h.h.sievertsen@bristol.ac.uk).
- For source files check the github repository [github.com/hhsievertsen/applied_econ_with_r](https://github.com/hhsievertsen/applied_econ_with_r).


**Other tutorials**

- I highly recommend the tutorials by Grant McDermott. For example [The R Intro (mainly for Stata users)](https://raw.githack.com/grantmcdermott/R-intro/master/rIntro.html) and [The R regression intro](https://raw.githack.com/grantmcdermott/R-intro/master/regression-intro.html). Grant has a also developed an impressive online resource of slides, notes, and examples on R, github, & Programming here: [Data science for economists](https://github.com/uo-ec607/lectures).



**Prerequisites**
  
1. Basic understanding of R. See  [R introduction](https://hhsievertsen.shinyapps.io/r_introduction/) for an introduction to R if you never used it before. 

2. I will not cover the theory behind the statistical methods used. Knowledge of econometrics at the level of (at least) [Wooldridge: Introductory Econometrics](https://www.goodreads.com/book/show/390475.Introductory_Econometrics) is therefore advantageous. 


I appreciate feedback, thanks.

Hans  (version 0.3 - November 30 , 2020)


<br><br><br><br><br><br>

# 1 Research Question  & Data



## 1.1 Research Question

Throughout this tutorial our empirical objective is to answer the following **fictitious** research question:
  
> Does attending a summer school improve test scores?
  
The research question will be addressed using a **fictitious simulated dataset**. 

## 1.2 The fictitious setting

The research question is inspired by papers such as [Matsudaira (2007)](https://www.sciencedirect.com/science/article/pii/S0304407607001194?casa_token=hnnF764CKPoAAAAA:5b9WhCManNDsdW4SmOHnnzNr0fZIarW8s6EsvpQW7MdUt470eNPmN2T8IFCsNc6Iajew5tEeNA) and the survey on interventions low SES students by  by [Dietrichson et al ( 2017)](https://journals.sagepub.com/doi/abs/10.3102/0034654316687036). 

The  **fictitious** setting is as follows:
  
  - In the summer break between year 5 and year 6, (corresponding to age 10) there is an optional summer school (or academic summer camp). 

- The  summer school  could be focusing on the school curriculum, or it could be focused on skills that lead to improved schooling outcomes (for example "grit" as in [Alan et al (2019)](https://academic.oup.com/qje/article-abstract/134/3/1121/5342089?redirectedFrom=fulltext)).

- The summer school is free, but enrollment requires actively involvement by parents.

- We are interested in whether participation in the summer school improves child outcomes. 

- The setting is a dream for  researchers (there is a reason why it is **fictitious**!):
  
* There was a Randomised Controlled Trial (*RCT*), where some families were randomised into receiving a letter reminding them of the summer school. We will exploit this for  **hypothesis testing**,  **regressions**, and applying an **instrumental variables** approach.

* We have test score measures before and treatment allowing us to test the effect of the summer school in a **difference-in-differences** approach.

* Pupils with test scores below 1.5 in year 5 were encouraged to participate in the summer school. This allows us to address the research question in a **regression discontinuity** approach.



## 1.3  The fictitious data

We have three datasets to study the research question:
  
  1.  [school_data_1.csv](https://raw.githubusercontent.com/hhsievertsen/applied_econ_with_r/main/data/school_data_1.csv) 

- We use this as example on how to **load data stored in a csv format**.
- This dataset contains information about person id, school id, an indicator variable that takes the value of 1 if the individual participated in the summer school, information about gender, parental income and parental schooling, and test scores in year 5 (before the treatment) and year 6. 


2.  [school_data_2.dta](https://github.com/hhsievertsen/applied_econ_with_r/raw/main/data/school_data_2.dta) 

- We use this as example on **how to load data stored in a Stata format**.
- This dataset contains information about person id, which enables us to link it to the first dataset. We will use this to practice **merging** data.
- The dataset also contains information about whether the individual received a reminder letter. 


3.  [school_data_3.xlsx](https://github.com/hhsievertsen/applied_econ_with_r/raw/main/data/school_data_3.xlsx) 

- We use this as example on how to **load data stored in a Microsoft Excel format**.
- This dataset contains information about person id, which enables us to link it to the first dataset. 
- The dataset also contains information about test scores in earlier (<5) and later years (>6).


Let's get started!

<br><br><br><br><br><br>


# 2 Loading & Cleaning the Data

## 2.1 Installing and loading a "package"

The first item on our to do list is to load the datasets. The first dataset is in a csv format. There are several ways to load a csv document into R. I am going to use `read_csv()` from the *readr* package. Before we can use this package we need to install it. We install a package with the `install.packages()` function, where we insert the name of the package in parenthesis. This procedure corresponds to *ssc install outreg* to install outreg in Stata. 

An important difference to Stata is that we also have to tell R to use the new package in every new session. We do that with `library()`. However we only have to install it once. So to install and load *readr* we run the following command:

```{r ch2-1,eval=F, include=T,echo=T}
install.packages("readr")
```

To load the *readr* package we run the following command:

```{r ch2-2,eval=F, include=T,echo=T}
library("readr")
```


## 2.2 Loading a csv data file 

Having installed *readr* we are now ready to use the `read_csv()` function to load our first dataset. We will load the dataset *school_data_1.csv* by inserting the path to the file in the parenthesis: 

```{r ch2-3,eval=F, include=T,echo=T, out.width=500,fig.align="center"}
# load readr
library("readr")
# load data
read_csv("C:/Users/hhs/school_data_1.csv")
```

Stata users would now expect that the dataset is loaded in the memory and everything I do now relates to this dataset. Stata users will be disappointed. When R executes the command above it loads the data, but then it says: "Hey, Hans didn't tell me what to do with the dataset, so I will just print the contents of it and forget it." 

While Stata (at least in older versions) is based on having one dataset loaded at a time, we can have many datasets loaded at once in R. Therefore, to identify the dataset we need to give it a name. In this example we tell R to store the new dataset under the name *school_data_1* I use the *assignment operator* `<-`, but `=` would also work. However, it is a good habit to use the assignment operator, because it makes life a bit easier once we get to scoping (if we get there). Ignore this for now, and move on.


```{r ch2-4,eval=F, include=T,echo=T, out.width=500,fig.align="center"}
# load readr
library("readr")
# load data and assign it to an object with the name school_data_1
school_data_1<-read_csv("C:/Users/hhs/school_data_1.csv")
```


Very good! I might ignore `library()` in subsequent code blocks and examples to save space. Once you've started R and you've run the `library()` command once, you don't have to run it again before you close and restart R again.

In Stata my first step after loading the data is typically to use *browse* to take a look at the data. In R we can do that with `View(school_data_1)`. I will not show that command here. Instead I will present the function `head()` that prints the head of the dataset with the first 6 rows. 

```{r ch2-5,eval=T, include=T,echo=T, out.width=500,fig.align="center"}
# Use head() to print first 6 observations of school_data_1
head(school_data_1)
```


## 2.3 Loading a Stata data file 

We will now load a Stata dataset into R. To load a *dta* file I will use the  `read.dta13()` function from the *readstata13* package. The syntax is then very similar to the `read_csv()` syntax. This time we will use `tail()` to show the last 8 observations.


```{r ch2-6,eval=F, include=T,echo=T}
# load readstata13
library("readstata13")
# use read.dta13 from readstata13 to load a Stata dataset
school_data_2<- read.dta13("C:/Users/hhs/school_data_2.dta")
# print the tail
tail(school_data_2,n=8)
```
```{r ch2-7,eval=T, include=T,echo=F}
tail(school_data_2,n=8)
```


  
## 2.4 Loading an xlsx file

Finally, we'll load the the *xlsx* file *school_data_3.xlsx* for that we'll use the `read.xlsx()` function from the *openxlsx* package. Again, the syntax is very similar to what we've seen before.  This time we will use the `glimpse()` function from the *dplyr* package to get a glimpse of the dataset. 


```{r ch2-8,eval=F, include=T,echo=T}
# Load openxlsx and dplyr
library("openxlsx")
library("dplyr")
# Use read.xlsx from openxlsx to load .xlsx file
school_data_3 <- read.xlsx("C:/Users/hhs/school_data_3.xlsx")
# use glimpse to get a "glimpse" of the loaded dataset
glimpse(school_data_3)
```
```{r ch2-9,eval=T, include=T,echo=F}

glimpse(school_data_3)
```


## 2.5 Merging the datasets

Let's now load the three datasets. We will use the `merge()` function for that. The function `merge()` is included in  *base* R. We therefore do not need to install and load any packages to use it. In merge we first state the names of the two datasets to merge. We then tell R the column(s) to use to merge the two datasets with `by=....`. As a default R includes all rows that are observed in both datasets (based on the by variable), but we can  set `all=TRUE` to keep all rows from both datasets, or `all.x=TRUE` to keep all rows from the first dataset and all rows that were merged, and finally `all.y=TRUE` to keep all rows from the second dataset. The default behaviour of R corresponds to using the option *keep(3)* in Stata, and Stata's default option corresponds to using `all=TRUE` in R. 

**Important difference to Stata:** A key difference between Stata and R merge is that in case a variable in the first dataset has the same name as a column in the second dataset, R will automatically rename the column names by adding suffices *.x* (the column from the first dataset) and *.y*  (the column from the second dataset). Stata just overwrites the columns. 

In the code block below we

1. Load the dataset *school_data_1.csv* as described above.
2. Load the dataset *school_data_2.dta* as described above.
3. Load the dataset *school_data_3.xlsx* as described above.
4. Merge *school_data_1* and *school_data_2* by the *person_id* column and save the merged dataset under the name *school_data*.
4. Merge *school_data_3* with *school_data* and overwrite *school_data*. Note in this case we merge by *person_id* and *school_id* columns. This is not necessary (because person_id is unique), but serves as an example on how to merge by more columns using `c()`.  name *school_data*.
5. Use the `summary()` function to obtain summary statistics of the variables.


```{r ch2-10,eval=T, include=T,echo=T, out.width=500,fig.align="center"}
# Merge school_data_1 and school_data_2 and save as school_data_merged 
school_data_merged<-merge(school_data_1,school_data_2,by="person_id")
# Merge school_data_3 with school_data_merged
school_data_merged<-merge(school_data_merged,school_data_3,by=c("person_id","school_id"))
# summary statistics
summary(school_data_merged)
```




<br>

<center>

<iframe src="https://giphy.com/embed/iXTrbbYMQBCMM" width="480" height="360" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/funny-star-trek-iXTrbbYMQBCMM"></a></p>
</center>


<br><br><br><br><br><br>

# 3 Tidying and processing the data

## 3.1 Tidying the data

Now that we have merged the datasets we want to make sure that the merged dataset satisfies the  [Tidy Data Principles](https://vita.had.co.nz/papers/tidy-data.pdf). 

To "make the the data tidy" we use the *tidyr* package and specifically, we use `pivot_longer()` which corresponds to *reshape long* in Stata.  See section 9.2 in my [R introduction](https://hhsievertsen.shinyapps.io/r_introduction/)  for details. 

```{r ch3-1,eval=F, warning=F,include=T,echo=T}
# load tidyr package
library("tidyr")
# make data tidy (make long)
school_data_tidy<-school_data_merged%>%
       pivot_longer(
         cols = starts_with("test_year"),
         names_to = "year",
         names_prefix = "test_year_",
         names_transform = list(year = as.integer),
         values_to = "test_score",
       )
# use head to view the first 6 observations 
head(school_data_tidy)
```

```{r ch3-2,eval=T, warning=F,include=T,echo=F,message=FALSE}
head(school_data_tidy)
```



## 3.2 Sample Selection

We now have a dataset that satisfies the tidy data principles. The next task before  is the sample selection.  The only sample selection we are concerned with in this exercise is missing values. We will use the `skim()` function  to assess how many missing values there are in our dataset.  `skim()` is one of my favourite functions in R to get an overview of the datasets, it comes  from the *skimr* package. 


```{r ch3-3  ,eval=T, message=F,warning=F,include=T,echo=T,  out.width=500,fig.align="center"}
# Load skimr
library("skimr")
# Use skim() to skim the data
skim(school_data_tidy)
```

 We can see how many observations and variables there are, the variable types, the number of missing values. The mean, standard deviations, percentiles, and we even get a small histogram. 

We notice that the variable *parental_schooling* has 45 missing values and the variable *test score*  has 11 missing values. Let's assume that these values are missing at random and remove the rows. Here we use `filter()` for that. 


```{r ch3-4  ,eval=T, include=T,echo=T,  out.width=500,fig.align="center"}
# Select only rows with no missing values
school_data_selected<-school_data_tidy%>%
                     filter(!is.na(parental_schooling),!is.na(test_score))
# Use apply to apply a function on all columns
apply(school_data_selected,2, function(x) sum(is.na(x)))
```

 There are many ways to assess the how many rows with missing values there are in our dataset, but in the example above I introduced the very popular `apply()` family in R. The apply function applies takes three arguments: an object (like a data frame), the dimension of the object to "loop over", the function to execute in each loop iteration. In our example we  tell R to consider the school_data object, the second dimension (columns), and on each column execute the function `sum(is.na(x))`.
 
This might seem overly complicated for a Stata user (like myself), but hey! How would you do this in Stata?  `apply()` is super useful as we can loop over objects in just one line. I called it a family, because of the siblings `lapply()`, `sapply()`, `tapply()`, and more. See [http://uc-r.github.io/apply_family](uc-r.github.io/apply_family) for details. 


Very good! We've now created a new dataset containing only complete cases. Let's now create a nice looking tab


## 3.3 Modifying the data

Our next step is to make some modifications to the data. First, we will rename the *summercamp* variable to *summerschool*. We do that with the `rename()` function (suprise!).

```{r ch3-5,eval=T, warning=F,include=T,echo=T,message=FALSE}
# rename summercamp to summerschool
analysisdata<-rename(school_data_selected, summerschool=summercamp)
# use head to view the first 6 observations 
head(analysisdata)
```

Brilliant. In the next step we want to transform our *test_score* variable to have mean of zero and a standard deviation of one. Importantly we want to do this standardization within year. In Stata this would be a task for *bys year:*. In Stata we first specify what variable to group the data on, and the apply the functions *sd* and *mean* on that level.


<details>
<summary>Help me Hans!</summary>
<div class="Stata">

I could have written the code block below as

<br>
# Group analysisdata by year
`analysisdata<-group_by(analysisdata,year)`
# Rename test_score to test_score_raw
`analysisdata<-rename(analysisdata,test_score_raw=test_score)`
# Create a new variable with mutate
`analysisdata<-mutate(analysisdata, test_score=(test_score_raw-mean(test_score_raw))/sd(test_score_raw))`

<br>

The functions such as `mutate()`, `select()` (not used here), `filter()` (not used here), `rename()`, and `group_by()` all take the dataset as the first argument. In the block above I overwrite analysisdata in every line with the modified dataset. In the block below I use the `%>%` (called the pipe operator) instead. It basically just moves the resulting dataset forward to the next dataset. 

</div>
</details> 

```{r ch3-6,eval=T, warning=F,include=T,echo=T,message=FALSE}
# Standardize test score
analysisdata<-analysisdata%>%
              group_by(year)%>%
              rename(test_score_raw=test_score)%>%
              mutate(test_score=(test_score_raw-mean(test_score_raw))/sd(test_score_raw))
# show mean of test_score
print(paste("Mean of test score:",mean(analysisdata$test_score)))
#show sd of test_score
print(paste("SD of test score:",sd(analysisdata$test_score)))
```

In the example above we use 

- `print()` to print output to the console (just like *display* in Stata). 
- `paste()` to concatenate elements together
- `analysisdata$test_score` to extract the variable *test_score* from the *analysisdata* dataset.
- `mean()` and `sd()` to calculate means and standard deviations. Note that this only works because we already removed the missing values. If we apply `mean()` on a vector that includes missing values it will return a missing value unless we specify the option `na.rm = FALSE`. 

<br><br><br><br><br><br>

# 4 Descriptive Statistics 

We've now managed to load *csv*, *dta*, and *xlsx* files. We've also managed to merge them, restructure the dataset so that it follows the Tidy Data Principles, and we have removed missing values. The next step in our empirical project is to create some tables and charts to describe the dataset. From now on we'll assume that the dataset is loaded.



Our goal is to create a table that shows means, standard deviations, and other statistics that gives us and the reader an impression of the dataset. We already know at least two ways to calculate summary statistics:
  
1. `summary()` from base R. This function actually works on a lot of object types in R. It always gives a good summary. But our goal is to create a table that we can include in a Microsoft Word or Latex document. 

2. `skim()` from the *skimr* package. 

## 4.1 A quick way to create a nice looking table

We will first use a cousin of `skim()` to create a table with summary statistics that can be exported to various formats, included Latex. The cousin comes from the *modelsummary* package and is called `datasummary_skim()`. Let's first create the default table:
```{r ch4-1,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
# load modelsummary
library("modelsummary")
# create a summary stat table
analysisdata%>%
  filter(year==2)%>%
  select(female,starts_with("paren"),letter,summerschool,test_score)%>%
  datasummary_skim()
```

Let's now change the appearance of the table and export it to Latex. When exporting it to Latex, we can't have histogram', so we disable them. We specify `output="tab_summary_statistics.tex"` to write to a latex file. We can also export the table to other formats like a Microsoft Word document. 

```{r ch4-2,eval=F, warning=F,include=T,echo=T,results="asis",message=FALSE}
# load modelsummary
library("modelsummary")
# create a summary stat table in Latex format
analysisdata%>%
  filter(year==2)%>%
  select(female,starts_with("paren"),letter,summerschool,test_score)%>%
  datasummary_skim( fmt="%.2f",
                 histogram=FALSE, output="tab_summary_statistics.tex")
```


The *tab_summary_statistics.tex* output looks as follows and is ready to be included in Latex:


```
\begin{table}[H]
\centering
\begin{tabular}[t]{lrrrrrrr}
\toprule
  & Unique (\#) & Missing (\%) & Mean & SD & Min & Median & Max\\
\midrule
female & 2 & 0 & 0.52 & 0.50 & 0.00 & 1.00 & 1.00\\
parental\_schooling & 12 & 0 & 11.32 & 1.10 & 10.00 & 11.00 & 23.00\\
parental\_lincome & 3486 & 0 & 14.56 & 0.69 & 12.67 & 14.52 & 19.45\\
letter & 2 & 0 & 0.25 & 0.43 & 0.00 & 0.00 & 1.00\\
test\_score & 3486 & 0 & 2.22 & 0.68 & -0.57 & 2.24 & 4.74\\
\bottomrule
\end{tabular}
\end{table}

```
Brilliant. But what if we want a table for Microsoft Word? We simply write `output="tab_summary_statistics.docx" instead.` 

## 4.2 Custom tables 

To customize our table of summary statistics a bit more we can use the function `datasummary()`. This function allows us to enter a *formula* expressing the layout of our table. Let's try it:

```{r ch4-3,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
# load modelsummary
library("modelsummary")
# create a summary stat table

datasummary(female+parental_schooling+parental_lincome+
              letter+test_score~Factor(summerschool)*(Mean+SD),
            sparse_header = FALSE,
            data=filter(analysisdata,year==2))
```

In the example above we

- List the variables to include separated with a +:`female+parental_schooling+pa...`

- Use a `~` to separate the list of variables from the formula.

- Use the formula `Factor(summerschool)*(Mean+SD)` to show that we want to show the mean and standard deviation separately for each values of the variable `summerschool`. We use `Factor()` to tell R that it should consider summerschool as a binary variable. We could also have done that in the data tidying process. We can also reverse the ordering `(Mean+SD)*Factor(summerschool)`, which would then first show the mean and standard deviation and then split by summerschool within these values. 

- Use `sparse_header = FALSE` to specify that we actually want to include the "summerschool" as a header. 


<br>

<center>

<iframe src="https://giphy.com/embed/n8SkNR77udWlG" width="480" height="333" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/star-trek-wow-spock-n8SkNR77udWlG"></a></p>

</center>

<br>

## 4.3 Variable names in tables

So far we've used variable names as labels in our table. In contrast to Stata, R allows for labels with white space, and we could therefore rename the variables to give nicer looking names in our table. However, we can also just assign a "label" when creating the table as shown below:

```{r ch4-5,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
# load modelsummary
library("modelsummary")
# create a summary stat table

datasummary((`Female`=female)+
            (`Parental schooling (years)`=parental_schooling)+
            (`Parental income (log)`=parental_lincome)+
            (`Received reminder letter`=letter)+
            (`Test Score`=test_score)~
            (`Attended summer school`=Factor(summerschool))*
              (Mean+SD),
            sparse_header = FALSE,
            data=filter(analysisdata,year==2))
```


## 4.4 Outputing to Microsoft Word or Latex

To save our `datasummary()` table to Microsoft Word or Latex, we use the same expression as with `datasummary_skim()`, as illustrated below: 

```{r ch4-6,eval=F, warning=F,include=T,echo=T,results="asis",message=FALSE}
# load modelsummary
library("modelsummary")
#library("flextable")
# create a summary stat table

datasummary((`Female`=female)+
            (`Parental schooling (years)`=parental_schooling)+
            (`Parental income (log)`=parental_lincome)+
            (`Received reminder letter`=letter)+
            (`Test Score`=test_score)~
            (Mean+SD+P25+P50+P75),
            sparse_header = FALSE,
            data=filter(analysisdata,year==2),
            output = 'tab_descriptive_statistics.docx')
```


## 4.4 Tables with Stargazer

Before I met the datasummary package in R I created my Latex tables with `stargazer()` from the *stargazer* package. This function is super easy to use. Let us try it! To create a table of summary statistics we simply provide `stargazer()` with a data frame. The only challenge now is that so far we have worked with so called [tibble](https://blog.rstudio.com/2016/03/24/tibble-1-0-0/#:~:text=There%20are%20two%20main%20differences,to%20work%20with%20large%20data) and not data frames. We therefore first have to convert it into a data frame which we do with `as.data.frame()` as shown below.

```{r ch4-7,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
# load stargazer
library("stargazer")
# prepare data for stargazer
data_for_stargazer<-analysisdata%>%
                    select(female,parental_schooling,parental_lincome,letter,test_score)%>%
                    filter(year==2)%>%
                    as.data.frame()
# create a summary stat table
stargazer(data_for_stargazer,type="html")
```

<br>
For more details about Stargazer [check the documentation here](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf). 
<br><br><br><br><br><br>

# 5 Descriptive Charts

The *ggplot* world is covered  in [R introduction](https://hhsievertsen.shinyapps.io/r_introduction/), but let us briefly cover a few charts here as well. You will also see more charts in later chapters.


## 5.1 A scatter plot

Our first chart is a scatter plot. We are just interested in whether test score is and parental income are correlated. We therefore create a scatter plot test scores in year 5 against parental income. We add a fitted line as well. 

In the following example we

1. Initiate a `ggplot()` object usign the *analysisdata* filtered to only include year 5.
2. Specify that *parental_lincome*  should be used on the x-axis and *test_score* on the y-axis in  `aes()` inside `ggplot()`.
3. Use `geom_smooth()` to include a fitted line.
4. Use `geom_point()` to add the scatter plot and set `alpha=0.1` to make it almost transparent. 
5. Use `theme_classic()` to apply the classic theme. 


```{r ch5-1,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE, out.width=400,fig.align="center"}
# load ggplot2
library("ggplot2")
# create a scatter plot with a fitted line
ggplot(analysisdata%>%filter(year==5),  
       aes(x=parental_lincome,y=test_score))+
       geom_smooth() +
       geom_point(alpha=0.1)+
       theme_classic()

```

## 5.2 Bar chart and boxplot

Okay, we observe that test score is correlated with parental income. That is not surprising. Now let's also create charts to assess whether summer school attendance is correlated with individual characteristics. We first create a scatter plot of parental schooling and test scores in year 5 (before the summer school). This is just like above, but with schooling instead of income. Secondly, we create a bar chart showing average test score in year 5 (before the summer school) by summer school attendance. Thirdly, we create box plots of parental income by summer school attendance. There are a few additional tricks in the following code:


- We first create the basic `ggplot()` object where we load the data and specify the theme. This object is called *rawchart*
- We then create 3 charts based on *rawchart*. Each chart is saved under a name.
- We use `geom_bar()` to create a bar chart. We set `stat="summary",fun="mean"` to tell R to create a bar chart showing the mean of *test_score*.
- We use `labs()` to specify the axes titles. 
- We use `geom_boxplot()` to create  a box plot.
- We use the patchwork package to combine several charts in one chart. 
- Use `ggsave()` to save the chart to a *png* file.




```{r ch5-2,eval=F, warning=F,include=T,echo=T,results="asis", out.width=600,fig.align="center"}
# Load patchwork 
library("patchwork")
# Create raw chart element
rawchart<-ggplot(analysisdata%>%filter(year==4),x=as.factor(fill))+
          theme_classic()
# Create bar chart of pre summer school test score and summer school 
p1<-rawchart+
       geom_smooth(aes(x=parental_schooling,y=test_score)) +
       geom_point(aes(x=parental_schooling,y=test_score),alpha=0.1)+
       labs(x="Parental schooling", y="Test Score Year 5")
# Create bar chart of pre summer school test score and summer school 
p2<-rawchart+
       geom_bar(aes(x=as.factor(summerschool),y=test_score),
                    stat="summary",fun="mean")+
       labs(y="Test Score Year 5", x="Attended Summer School")
# Create bar chart of parental schooling and summer school attendance
p3<-rawchart+
              geom_boxplot(aes(x=as.factor(summerschool),y=parental_lincome))+
       labs(y="Parental Income (log)", x="Attended Summer School")
# Combine charts
p1/(p2+p3)
# Export chart
ggsave("fig1.png")
```
```{r ch5-3,eval=T, warning=F,message=F,include=T,echo=F,results="asis", out.width=600,fig.align="center"}
# Load patchwork 
library("patchwork")
# Create raw chart element
rawchart<-ggplot(analysisdata%>%filter(year==4),x=as.factor(fill))+
          theme_classic()
# Create bar chart of pre summer school test score and summer school 
p1<-rawchart+
       geom_smooth(aes(x=parental_schooling,y=test_score)) +
       geom_point(aes(x=parental_schooling,y=test_score),alpha=0.1)+
       labs(x="Parental schooling", y="Test Score Year 5")
# Create bar chart of pre summer school test score and summer school 
p2<-rawchart+
       geom_bar(aes(x=as.factor(summerschool),y=test_score),
                    stat="summary",fun="mean")+
       labs(y="Test Score Year 5", x="Attended Summer School")
# Create bar chart of parental schooling and summer school attendance
p3<-rawchart+
              geom_boxplot(aes(x=as.factor(summerschool),y=parental_lincome))+
       labs(y="Parental Income (log)", x="Attended Summer School")
# Combine charts
p1/(p2+p3)
```

The three charts above show us that test scores are correlated with parental background (the scatter plot), that those who attended the summer school  had better test scores before the summer school, and  that parental account is correlated with summer school attendance (the box plot). In short:

```{r , echo=FALSE, fig.cap=" ", out.width = '40%',fig.align='center'}
knitr::include_graphics("images/selectionbias.png")
```

## 5.3  Histogram & density  charts
Let's compare the test score distribution in year 6 (after the summer school) for those who attended the summer school with those who did not. We create a histogram and add a line showing the estimated density distributions. We also change the colour scheme, the legend labels, the legend poistion, and a few minor tweaks. 

```{r ch5-4,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE, out.width=500,fig.align='center'}

# create a histogram and density chart
ggplot(analysisdata%>%filter(year==6),
       aes(x=test_score,fill=as.factor(summerschool)))+
       geom_histogram(aes(y=..density..),bins = 50,alpha=0.5,
                       position="identity",color="white")+
       geom_density(alpha=0.0,size=1,show_guide= FALSE)+
       theme_minimal()+
       labs(y="Density",x="Test score",fill=" ")+
       scale_fill_brewer(palette="Set2",labels=c("No summer school","Summer school"))+
       theme(legend.position="top")
  
```

## 5.4  The Joy Division Album Cover chart

```{r , echo=FALSE, fig.cap=" ", out.width = '40%',fig.align='center'}
knitr::include_graphics("images/joydivision.png")
```

The next chart is inspired by a Joy Division album cover unknown pleasures (read more [here](https://blogs.scientificamerican.com/sa-visual/pop-culture-pulsar-origin-story-of-joy-division-s-unknown-pleasures-album-cover-video/)). We use ` geom_density_ridges()` from the *ggridges* package.

Our goal is to compare the test score distribution for those who received the summer school reminder letter with those who did not. We are already making a step into the next chapter and assessing at the Randomized Control Trial in two dimensions. First, the test score comparisons before year 6 are informative about whether the randomization worked. Secondly, the test score comparisons from year 6 and later are informative about the reduced form effect. 


```{r ch5-5,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE, out.width=750,fig.align='center'}
# Load ggridges
library("ggridges")
# create a ggridges  chart
ggplot(analysisdata,aes(y=as.factor(year),x=test_score,fill=as.factor(letter) ))+
        geom_density_ridges(  alpha = .7, scale=1.5,color = "white", from = -2.5, to = 2.5)+
        theme_minimal()+
        theme_ridges(grid = FALSE)+
  scale_y_discrete(expand = c(0, 0)) +
  scale_x_continuous(expand = c(0, 0)) +
        scale_fill_brewer(palette="Set1",labels=c("No letter","Letter"))+
        labs(x="Test Score",y="Year",fill=" ",
            title="Test score distribution by reminder letter status  & year")+
        theme(legend.position="top",aspect.ratio=4/3,plot.title = element_text(hjust = 0.5))
  
```

The chart above tells a convincing story. In the first five years the distribution of test scores is essentially identical across those who received and those who did not receive a reminder letter. That indicates that the randomisation worked as intended. After year 5 the test score distribution of those who received a reminder letter shifted to the right compared to those who did not receive a letter suggesting a reduced form effect of the letter on our outcome. Let's analyse that in the next sections. 

<br><br><br><br><br><br>

# 6 Balancing table

The last chart suggested that the letter that was randomly sent to some families to remind them about the summer school worked. The test score distribution of the children that received the letter shifted to the right. Importantly, the charts also suggested that there was no difference prior to the summer school. Let us now test that formally. 

## 6.1 Pairwise t-test

We can conduct a t-test in R using `t.test()`. Specifically, we specify the formula `test_score~summerschool` to test whether the average *test_score* is significantly different across the two groups specified by *summerschool*. Let's do that for year 5 data:

```{r ch6-1,eval=T, warning=F,include=T,echo=T,message=TRUE}
# Filter year 5
df<-analysisdata%>%filter(year==5)
# Conduct a t test
t.test(test_score~letter,data=df)
```
The test suggest that the mean test score prior to summer school was not difference across letter receivers and not receivers. Promising!

One feature of R that I really appreciate (especially compared to Stata) is that I can skip steps and directly insert functions within other functions. For example if I know that I am not going to use the selected dataset again, we don't need to create it first. We can simply specify the selection criteria in the data argument of `t.test()` as shown below (we also did that in the charts above)

```{r ch6-2,eval=T, warning=F,include=T,echo=T,message=TRUE}
# Conduct a t test on analysisdata restricted to year 4
t.test(test_score~letter,data=analysisdata%>%filter(year==4))
```

## 6.2 A publication ready table of mean comparisons

If we want to create a nice looking balancing table and insert it in Latex or Word, we can use `datasummary_balance()` from the *modelsummary* package. We load the *estimatr* package because it enables `datasummary_balance()` to calculate and include the pairwise t-tests.


```{r ch6-3,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
# t test
library(modelsummary)
library(estimatr)
# Filter and modify data
testdata<-analysisdata%>%
         filter(year==5)%>%
         ungroup()%>%
         mutate(Treated=ifelse(letter==1,"Letter","No Letter"))%>%
         select(female,parental_schooling,parental_lincome,test_score,Treated)%>%
         rename(`Female`=female,
          `Parental schooling (years)`=parental_schooling,
          `Parental income (log)`=parental_lincome,
          `Test Score`=test_score)
     
# Table with balancing test
datasummary_balance(~Treated,
                    data = testdata,
                    title = "Balance of pre-treatment variables",
                    notes = "Notes: This is a brilliant table!",
                    fmt= '%.5f',
                    dinm_statistic = "p.value")


```
The table suggests that all variables are well balanced across treated (receiving a letter) and untreated. 

As before, we can simply add the option `output=tab_balancing.docx` if we want to export the table to Microsoft Word, or `output=tab_balancing.tex` if we want a Latex table.


<br><br><br><br><br><br>

#  7 Ordinary Least Squares 


Our goal is now to estimate the following reduced form relationship between test score in year 6 and an indicator for receiving a reminder letter using Ordinary Least Squares (OLS)

$testscore_i=\beta_0+\beta_1Letter_i+u_i$.



## 7.1 OLS estimation with with `lm()` 

We can run OLS  with `lm()` (linear models). We first enter a formula of the form:

- `y~x1+x2+...`

followed by the 

- `data=...` command.

Below is an example based on a univariate regression between testscore and the indicator for receiving the letter.

```{r ch7-1,eval=T, warning=F,include=T,echo=T,message=FALSE}
# Ordinary Least Squares regression
lm(test_score~letter,data=analysisdata%>%filter(year==6))
```

The output from `lm()` is a bit disappointing.  But fear not. We can use the universal `summary()` function to get a bit more information out of `lm()`:

```{r ch7-2,eval=T, warning=F,include=T,echo=T,message=FALSE}
# Summary of Ordinary Least Squares regression
summary(lm(test_score~letter,data=analysisdata%>%filter(year==6)))
```

A nice feature of R is that we can assign basically everything to a name and then use it later. In the code block below we first run a regression and store it under the name *model1*. We then later call these regression results back when using the `summary()` command. In the following example we include a few covariates in the regression: 

```{r ch7-3,eval=T, warning=F,include=T,echo=T,message=FALSE}
#  Ordinary Least Squares regression
model1<-lm(test_score~parental_schooling+parental_lincome+letter+female,data=analysisdata%>%filter(year==6))
# Summary of model1
summary(model1)
```

## 7.2 OLS with the felm() function

I am a big fan of running regressions with **reghdfe** if in Stata. Luckily R has something quite similar. That is `felm()` from the *lfe* package. This function expects a formula of the form:

- `y~x1+x2+..|fixed effects|IV specification|cluster variables`

If we don't have fixed effects, an IV specification, or cluster variables, we simply 
insert a 0. See (The FELM documentation for extensive explanations)[https://www.rdocumentation.org/packages/lfe/versions/2.8-5.1/topics/felm].

In the following example we run a linear regression without fixed effects, but standard errors clustered on the school level. We specify `cmethod="reghdfe"` to mimic the clustering approach of *reghdfe*.

```{r ch7-4,eval=T, warning=F,include=T,echo=T,message=FALSE}
# Load packages
library(lfe)
# Select data
regdata<-analysisdata%>%filter(year==6)
# Regression
m1<-felm(test_score~letter+parental_lincome+female+parental_schooling|0|0|school_id
            ,data=regdata, cmethod="reghdfe")
# Summary of regression
summary(m1)
```

Brilliant. We let's now try to output such regressions to a nice looking table. We use the `modelsummary()` function from *modelsummary* for that. In the following example we


1. Run two regressions and store them as *models*.

2. Use `modelsummary()` to output the results of the regression results stored in *models*.

3. Specify that `modelsummary()` excludes the coefficient on the intercept.

4. Specify that parentheses should include standard errors with `statistic='std.error'`.

5. Specify the formatting of the numbers with `fmt=..`.

6. Use *flextable* to format the layout (lines etc)

```{r ch7-5,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
# Load flextable and modelsummary
library(flextable)
library(modelsummary)
# Regressions
models<-list(
  m1<-felm(test_score ~letter+parental_schooling+parental_lincome+female|0|0|school_id
            ,data=regdata, cmethod="reghdfe"),
  m2<-felm(test_score ~letter+parental_schooling+parental_lincome+female|
              school_id+year|0|school_id,data=regdata, cmethod="reghdfe")
  )
# Generate table
modelsummary(models, stars = TRUE,statistic = 'std.error',
             fmt= '%.4f',
              coef_omit= '(Intercept)', output = 'flextable')
```

Just like in earlier examples, we can output our table to Microsoft Word or Latex with `output=..`. Note that we specify the type of standard errors in the `modelsummary()` function. Note that you can also use  [Stargazer](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf) for regression tables.
<br><br>
Brilliant!  The results show that those received a letter have a 0.2SD higher test score in year 6. There are many other settings that we can specify to polish our table. But let us  move on.

<br><br><br><br><br><br>

# 8 The first stage with OLS &  Logit/Probit

Okay, from section 6 we conclude that the randomisation worked and that receiving the letter is as good as random. From section 7 we know that those that received a letter have a 0.2SD higher test score in year 6. But that is the intend to treat effect. Let us now scale that by the first stage effect. We are interested in the link between receiving a letter and attendign the summer school: 

$$summerschool_i=g(letter_i)$$



## 8.1 Estimating the LPM with OLS

Let us first consider the linear probability model and estimate

$$summerschool_i=\beta1+\beta_2letter_i+\gamma'X_i+u_i$$

We already know how to do that. We can use `lm()` or `felm()`, but let us use this as a change to add a row with the mean of the dependent variable. We do that by calculating the statistics we want to add and add them to the table with `add_rows=...` as shown below. 


```{r ch8-1,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
# Estimate LPM (the first stage)
models<-list(
  m1<-felm(summerschool ~letter+parental_schooling+parental_lincome+female|0|0|school_id
            ,data=regdata, cmethod="reghdfe"),
  m2<-felm(summerschool ~letter+parental_schooling+parental_lincome+female|
              school_id+year|0|school_id,data=regdata, cmethod="reghdfe")
  )
# Store the mean of dependent variable in a data frame
added_stats<-tibble("Mean of Dep. ",m1=mean(regdata$summerschool),m2=mean(regdata$summerschool))
# Generate table
modelsummary(models, stars = TRUE,statistic = 'std.error',  
             fmt= '%.4f',add_rows = added_stats,
              coef_omit= '(Intercept)', output = 'flextable')
```


## 8.2 Logit & Probit

We can use `glm()` to estimate logit and probit models. We specify the link function as option as shown below for probit. 

```{r ch8-2,eval=T, warning=F,include=T,echo=T,message=FALSE}
##  Estimate a binary outcomes model using a probit
probit_results <- glm(summerschool ~letter, data = regdata, family = binomial(link="probit"))
# Print the results
summary(probit_results)

```

and for logit (now with more controls)...

```{r ch8-3,eval=T, warning=F,include=T,echo=T,message=FALSE}
##  Estimate a binary outcomes model using a logit
logit_results <- glm(summerschool ~letter+parental_lincome+female+parental_schooling, data = regdata, family = binomial(link="logit"))
# Print the results
summary(logit_results)
```

Note that the output about covers the beta coefficients. Let's compute the average marginal effects.

## 8.3 Marginal effects

We can use `margins()` to obtain average marginal effects. We simply use the `margins()` function on the objects storing or probit and logit estimates. We can also include these directly in a nice looking table. 

```{r ch8-4,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
## Load margins package
library("margins")
##  Compute marginal effects
mfx_logit<- margins(logit_results)
mfx_probit<-margins(probit_results)
# Include in table
modelsummary(list(mfx_logit,mfx_probit), output = 'flextable')

```

The results show that receiving a reminder letter increases the likelihood of summer school attendance by 40-44 percentage points. The LPM coefficient is slightly larger than the Logit and Probit average marginal effects. 

<br><br><br><br><br><br>

#  9. Instrumental Variables

We estimated the reduced form relationship between receiving a reminder letter and test scores to be 0.2SD. We have also estimated the first stage to be around 0.4. We would therefore conclude that attending the summer school increases test scores by about 0.2SD/0.4=0.5SD.

Let us estimate the instrumental variable specification explicitly. I will show you two methods. 

## 9.1 IV using the  ivreg() function. 

We first use the `ivreg()` function from the *AER* package. AER does not refer to the American Economic Review, but to Applied Economics with R. The syntax is as follows

- `ivreg(outcome equation| exogenous variables, data)`

```{r ch9-1,eval=T, warning=F,include=T,echo=T,message=FALSE}
# Load the AER package
library(AER)
# Estimate IV specification with
summary(ivreg(test_score~summerschool+female+parental_lincome+parental_schooling|
                         female+parental_lincome+parental_schooling+letter,data=regdata))
```
The estimate is very close to the 0.5 we obtained above at 0.46SD. Note that we could be a bit skeptical about the standard errors above. 

### 9.2 IV using the  felm() function. 

Let us now reuse the `felm()` function. Just like we can use *reghdfe* in Stata for IV, `felm()` also allows us to estimate IV specifications, as explained in section 7.2. 


```{r ch9-2,eval=T, warning=F,include=T,echo=T,message=FALSE}

# Estimate IV specification with felm 
m1<-felm(test_score~parental_lincome+female+parental_schooling| # Outcome eq.
           school_id|                                           # Fixed effects
           (summerschool~letter)|                               # First stage eq.
           school_id                                            # Cluster var
            ,data=regdata, cmethod="reghdfe")
# Summary of results
summary(m1)
```
The coefficient is now slightly larger at 0.47SD. The key difference is that we include fixed effects. Note that `felm()` tells us that the F-stat on the excluded instrument is 63. Moreover, we also have clustered standard errors now. 


## 9.3 A complete IV table

Let us finish the IV section by creating a complete IV table showing the raw correlation between test score and summer school attendance, the reduced form, the first stage, and the IV estimate. 

Note that in the example below we use `coef_map=` to rename coefficients, specify the coefficients to include, and to let two coefficients with different names appear in the same row (*summerschool1* and *summerschool(fit)* ).

```{r ch9-3,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
library("gt")
# Estimate OLS
OLS<-felm(test_score~summerschool+parental_lincome+female+parental_schooling|school_id|0|school_id,data=regdata)
# Estimate reduced form 
RF<-felm(test_score~letter+parental_lincome+female+parental_schooling|school_id|0|school_id,data=regdata)
# Estimate first stage 
FS<-felm(summerschool~letter+parental_lincome+female+parental_schooling|school_id|0|school_id,data=regdata)
# Estimate IV specification 
IV<-felm(test_score~parental_lincome+female+parental_schooling| # Outcome eq.
           school_id|                                           # Fixed effects
           (summerschool~letter)|                               # First stage eq.
           school_id                                            # Cluster var
            ,data=regdata, cmethod="reghdfe")
# Combine results
IVresults<-list("OLS"<-OLS,"RF"<-RF,"FS"<-FS,"IV"<-IV)
# Coefficients
cm <- c('`summerschool(fit)`' = 'Summer School',
        'summerschool' = 'Summer School','parental_lincome' = 'Parental Income', 
        'letter' = 'Reminder letter', "female"="Female","parental_schooling"="Parental Schooling")
# Output Table
modelsummary(IVresults, stars = TRUE,statistic = 'std.error',  
             fmt= '%.4f',coef_map=cm, output = 'gt'
        )
```

The first column shows that ignoring the selection problem and estimating the relationship between test score and summer school conditional controls, leads to a coefficient of 0.78SD. As expected this coefficient is larger than the IV estimate of 0.47SD shown in the fourth column of the table. The descriptive charts in chapter 5 suggested that the children who attended the summer school already had better test scores before the summer school and that their parents have higher incomes and completed more years of education. The coefficient in the first column above is therefore likely capturing not only the causal effect of the summer school but also other unobserved characteristics that are positively linked to test scores and summer school attendance. 

<br><br><br><br><br><br>

#  10 Difference-in-Differences


Our IV story analysis was quite convincing. It is based on a fictitious RCT and the coefficent was smaller than the "naive OLS" as we expected. But let us not stop there. Let us also exploit that we have test scores of the children both before and after the summer school. We can therefore estimate a difference-in-differences specification:

$$test_score=\beta1+\beta_2summerschool_i+\beta_3after_i+\beta_4after_i\times summerschool+\gamma'X_i+u_i$$

Where after refers to test scores after attending the summer school. 

##  10.1 Inspecting the common trends

A crucial assumption behind the difference-in-differences approach is that the treated and control groups would have similar developments over time in the absence of treatment. We therefore want to create line charts of test scores over year to see whether the trends are similar in years without treatment. 

We use this as a change to first collapse the data on the year times summerschool level using `group_by()` and `summarise()`. In the example below we also

- Use `theme_wsj()` from the *ggthemes* package to apply the chart sheme from the Wall Street Journal.
- Use `geom_line()` to create a line chart.
- Use `geom_point()` to add points to the line chart.
- Use `geom_vline()` to add a vertical line. 
- Use `guides()` to combine the colour and shape legends. Let's now create  line chart showing the test score by year. We use this 

```{r ch10-1,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE, out.width=550,fig.align='center'}
# Load ggthemes
library("ggthemes")
# Collapse data on year level
collapsed_data<-analysisdata%>% 
                group_by(year,summerschool)%>%
                summarise(test_score=mean(test_score))
# create a line chart
ggplot(collapsed_data,aes(x=year,y=test_score,color=as.factor(summerschool),group=as.factor(summerschool)))+
      geom_line(size=1)+ylim(-1,1)+
      geom_point(aes(shape=as.factor(summerschool)),size=3)+
      theme_wsj()+
      theme(legend.position="top",axis.title = element_text(size=13))+
      labs(color="",x ="Year", y="Test core")+
      scale_color_manual(guide = "legend", values=c("#0e0e0e","#8a8a8a"),
                         labels=c("No Summer School","Summer school"))+
      geom_vline(xintercept=5.5, linetype="dotted",color="red")+
      guides(shape=FALSE,colour = guide_legend(override.aes = list(shape = c(16, 17),
         shape = c(16,17))))




```

We observe a small drop in the treatment group just before the summer school and a small increase in the control group. That looks a bit worrying, but otherwise the trends are very similar. 

## 10.2 Estimating the Difference-in-Differences model


We will now use the `felm()` function to estimate the the difference-in-differences specification. We first modify the data to create an after indicator, using `mutate()` and `ifelse()`. Secondly, we estimate 3 different difference-in-differences specifications. The first approach is the traditional approach with after, after X treated, and treated indicators. In the second approach we include year fixed effects instead of the after dummy. In the third approach we add controls. 

```{r ch10-2,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE}
library("gt")
# Modify data
df<-analysisdata%>%
    mutate(after=ifelse(year>5,1,0),
           afterXsummerschool=after*summerschool)%>%
           rename(school=summerschool)
# Estimate DiD without controls and fixed effects
m1<-felm(test_score~school+afterXsummerschool+after|0|0|school_id,data=df)
# Estimate DiD without controls
m2<-felm(test_score~school+afterXsummerschool|school_id+year|0|school_id,data=df)
# Estimate DiD 
m3<-felm(test_score~afterXsummerschool+school+parental_lincome+female+parental_schooling
         |school_id+year|0|school_id,data=df)
# Leave year 5 out to avoid dip
m4<-felm(test_score~afterXsummerschool+school+parental_lincome+female+parental_schooling
         |school_id+year|0|school_id,data=df%>%filter(year!=5))

# Coefficients
cm <- c('afterXsummerschool'  = 'Summer School X After',
        'school'        = 'Summer School',
        'after'='After')
# Output Table
modelsummary(list(m1,m2,m3,m4), stars = TRUE,statistic = 'std.error',  
             statistic_override = vcov,
             fmt= '%.4f',coef_map=cm, output = 'gt'
        )
```
 The treatment effects estimate are all around 0.6SD, which is slightly larger than the IV estimate, but smaller than the "naive OLS. The last column above shows the DiD estimate excluding year 5 where we observe the worrying deviations from the trend. As expected, this specification gives a slightly smaller coefficient of 0.54SD. 


<br><br><br><br><br><br>

#  11 Regression Discontinuity

We have evidence from an RCT and from a difference-in-differences approach. But we love data and quasi-experimental variation. We know  with test scores below 1.5 in year 5 were encouraged to participate in the summer school. We will exploit this in a regression discontinuity approach.
 

## 11.1 A RDD plot 

We start by plotting the share who participated in the summer school around the cutoff. We do this with `geom_point()` and `geom_smooth()`. But we first create two new datasets. One that is collapsed on the test score level and one that is just selected to region around the cutoff. 

```{r ch11-1,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE, out.width=600,fig.align='center'}
# Create dataset collapsed on bins
rdd_collapsed<-analysisdata%>%
     filter(year==5)%>%
     mutate(test_score=floor(test_score_raw*10)/10)%>%
     group_by(test_score)%>%
     summarise(summerschool=mean(summerschool))%>%
     filter(test_score>0,test_score<2.5)
# Selected range
rdd_raw<-analysisdata%>%
     filter(year==5)%>%
     filter(test_score_raw>0,test_score_raw<2.5)

# Create RDD plot
ggplot()+
    geom_smooth(rdd_raw%>%filter(test_score_raw<1.5),
                mapping=aes(x=test_score_raw,y=summerschool),method="lm", color="black")+    
    geom_smooth(rdd_raw%>%filter(test_score_raw>1.5),
                mapping=aes(x=test_score_raw,y=summerschool),method="lm", color="black")+    
    geom_point(rdd_collapsed,mapping=aes(x=test_score,y=summerschool),alpha=0.5)+
    ylim(-0.5,1.5)+
    theme_minimal()



```


<center>

<div class="tenor-gif-embed" data-postid="12385898" data-share-method="host" data-width="60%" data-aspect-ratio="1.3559322033898304"><a href="https://tenor.com/view/roller-coaster-state-fair-screaming-gif-12385898">Roller Coaster State Fair GIF</a> from <a href="https://tenor.com/search/rollercoaster-gifs">Rollercoaster GIFs</a></div><script type="text/javascript" async src="https://tenor.com/embed.js"></script>

Looks convincing! There is a clear drop in the probability of treatment around the cutoff of 1.5.



</center>

## 11.2 Balanced covariates & manipulation in forcing variable

Before we estimate the RDD we first check whether parental background is balanced over the discontinuity and that there is no evidence of manipulation of the forcing variable. 

The follow code block is long, but you should be able to understand all steps involved. 

```{r ch11-2,eval=T, warning=F,include=T,echo=T,results="asis",message=FALSE, out.width=750,fig.align='center'}
# Create dataset collapsed on bins
rdd_collapsed<-analysisdata%>%
  filter(year==5)%>%
  mutate(test_score=floor(test_score_raw*10)/10)%>%
  group_by(test_score)%>%
  summarise(parental_schooling=mean(parental_schooling),
            parental_lincome=mean(parental_lincome))%>%
  filter(test_score>0,test_score<2.5)

# Selected range
rdd_raw<-analysisdata%>%
  filter(year==5)%>%
  filter(test_score_raw>0,test_score_raw<2.5)

# Create RDD plot of parental income
p1<-ggplot()+
  geom_smooth(rdd_raw%>%filter(test_score_raw<1.5),
              mapping=aes(x=test_score_raw,y=parental_lincome),method="lm", color="black")+    
  geom_smooth(rdd_raw%>%filter(test_score_raw>1.5),
              mapping=aes(x=test_score_raw,y=parental_lincome),method="lm", color="black")+    
  geom_point(rdd_collapsed,mapping=aes(x=test_score,y=parental_lincome),alpha=0.5)+
  theme_minimal()+labs(title="Parental Income (log)")

# Create RDD plot of parental schooling
p2<-ggplot()+
  geom_smooth(rdd_raw%>%filter(test_score_raw<1.5),
              mapping=aes(x=test_score_raw,y=parental_schooling),method="lm", color="black")+    
  geom_smooth(rdd_raw%>%filter(test_score_raw>1.5),
              mapping=aes(x=test_score_raw,y=parental_schooling),method="lm", color="black")+    
  geom_point(rdd_collapsed,mapping=aes(x=test_score,y=parental_schooling),alpha=0.5)+
  theme_minimal()+labs(title="Parental Schooling (years)")

# Histogram of forcing variable
p3<-ggplot(rdd_raw,aes(x=test_score_raw))+
  geom_histogram(bins=100,color="white")+
  geom_vline(xintercept=1.5)+
  theme_minimal()+labs(title="Distribution of the forcing variable")

# Patchwork  to combine charts  
(p1+p2)/p3


```

Looks pretty balanced to me! 

## 11.3 RDD regression 

Finally we estimate an (old-fashioned) RD model as an IV with linear trends on both sides of the cutoff. To achieve this we first create a new dataset where the forcing variable is added as a separate collum

```{r ch11-3,eval=T, warning=F,include=T,echo=T,message=FALSE, out.width=750,fig.align='center'}

# "Forcing variable" data
year5<-analysisdata%>%
  filter(year==5)%>%
  mutate(above=ifelse(test_score_raw>1.5,1,0), ie=test_score_raw*above, score=test_score_raw)%>%
  ungroup()%>%
  select(person_id,above,test_score_raw,ie,score)
# Merge  forcing variable data to main data
df<-merge(analysisdata,year5,by="person_id")
df<-df%>%
  filter(year==6)%>%
  rename(summerschoolrdd=summerschool) # Rename to allow reuse later
        
    
# RDD regression
m_rdd<-felm(test_score~ie+score|0|(summerschoolrdd~above)|school_id,data=df)
summary(m_rdd)

```

The RDD coefficient suggest that the summerschool improves test scores by 0.5SD. 

<br><br><br><br><br><br>


# 12 Comparing all coefficients in  a plot

Let us end  our analysis by comparing the estimated causal effect of the summer school based on the various approaches in a chart using `modelplot()`. 

```{r ch12-1,eval=T, warning=F,include=T,echo=T,message=FALSE, out.width=650,fig.align='center'}

# Combine all "preferred specifications"  in a list
models<-list()
models[['OLS']]<-OLS
models[['RCT']]<-IV
models[['DiD']]<-m4
models[['RDD']]<-m_rdd


# Coefficient renaming
cm <- c('`summerschool(fit)`'  = 'RCT',
        '`summerschoolrdd(fit)`'  = 'RDD',
        'afterXsummerschool'='DiD',
        'summerschool'='OLS')

# Create plot of coefficients
modelplot(models,coef_map=cm)+
  labs(title="Coefficients: The effect of attending a summer school on test scores (in SD)",
       caption ="Note: All data is fictitious.")+
  theme(legend.position = "none")+
  geom_vline(xintercept=0)

```



# Stata index

- **bys year: egen x=..** An R example is provided in [section 3.3](https://hhsievertsen.github.io/applied_econ_with_r/#33_Modifying_the_data) <br>
- **collapse**:  An R example is provided in [section 10.1](https://hhsievertsen.github.io/applied_econ_with_r/#101_Inspecting_the_common_trends) <br>
- **merge**:  An R example is provided in [section 2.5](https://hhsievertsen.github.io/applied_econ_with_r/#25_Merging_the_datasets) <br>
- **import csv**:  An R example is provided in [section 2.2](https://hhsievertsen.github.io/applied_econ_with_r/#22_Loading_a_csv_data_file) <br>
- **import xlsx**:  An R example is provided in [section 2.4](https://hhsievertsen.github.io/applied_econ_with_r/#24_Loading_an_xlsx_file) <br>
- **margins **:  An R example is provided in [section 8.3](https://hhsievertsen.github.io/applied_econ_with_r) <br>
- **reg y x**:  An R example is provided in [section 7.1](https://hhsievertsen.github.io/applied_econ_with_r/#71_OLS_estimation_with_with_lm()) <br>
- **reghdfe y x,absorb() cluster()**:  An R example is provided in [section 7.2](https://hhsievertsen.github.io/applied_econ_with_r/#72_OlS_with_the_felm()_function) <br>
- **use "... .dta"**:  An R example is provided in [section 2.3](https://hhsievertsen.github.io/applied_econ_with_r/#23_Loading_a_Stata_data_file) <br>


<br><br><br><br><br>
**That is it!** You made it to the end of my tutorial. Well done!
<br>
<center>

<iframe src="https://giphy.com/embed/mGK1g88HZRa2FlKGbz" width="480" height="400" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/Friends-episode-1-season-9-friends-tv-mGK1g88HZRa2FlKGbz"></a></p>


<strong> Thanks!</strong><br><br>

I would like to thank @stsumej, Grant McDermott, and Jacob Mazalale for identifying mistakes and/or suggesting improvements. E-mails about mistakes and suggestions for improvements are always very welcome and much appreciated. You can write to h.h.sievertsen@bristol.ac.uk. Thank you. 
</center>


